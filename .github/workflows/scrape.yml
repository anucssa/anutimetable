name: Scrape official timetable

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *" # daily

jobs:
  scrape:
    runs-on: ubuntu-latest
    name: Scrape data into JSON file with Python script
    env:
      TIMETABLE_PREFIX: http://timetabling.anu.edu.au/sws
    strategy:
      fail-fast: false
      matrix:
        year: [2022]
        session: ['1 S1', '2 S2', '3 X1', '4 X2', '5 X3', '6 X4']
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-python@v2
        with:
          python-version: "3.8"

      - name: Install pipenv
        run: python -m pip install pipenv

      - name: Install dependencies
        working-directory: scraper
        run: python -m pipenv install --system

      - name: Run scraper script
        working-directory: scraper
        env:
          TIMETABLE_PREFIX: ${{ env.TIMETABLE_PREFIX }}
          YEAR: ${{ matrix.year }}
          SESSION: ${{ matrix.session }}
        run: python3 ./scraper.py $TIMETABLE_PREFIX$YEAR/ $SESSION

      - name: Compare existing and new data
        id: compare
        continue-on-error: true
        working-directory: scraper
        env:
          YEAR: ${{ matrix.year }}
          SESSION: ${{ matrix.session }}
        run: cmp timetable.json ../public/timetable.json

      - name: Commit to repo if data has changed
        if: ${{ steps.compare.outcome == 'failure' }}
        env:
          GH_USER: pl4nty
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          cd scraper
          mv -f ./timetable.json ../public/timetable_${YEAR}_${SESSION#* }.json
          git config user.name github-actions
          git config user.email 41898282+github-actions[bot]@users.noreply.github.com
          git remote set-url origin https://pl4nty:$GH_PAT@github.com/$GITHUB_REPOSITORY.git
          git add --all
          git commit -m "Add new timetable data"
          git push origin
